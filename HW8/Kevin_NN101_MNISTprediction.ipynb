{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kevin610-cpu/FDSFE_KCarter/blob/main/HW8/Kevin_NN101_MNISTprediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this homework is to create three neural network to solve the same problem and compare the performance of each. The problem is the classic prediction of hand written digits. We use the MNIST benchmark dataset which contains 60,000 images of handwritten digits and the corresponding labels"
      ],
      "metadata": {
        "id": "jrZz8vX-m7iG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gfUuRbTECORT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download the data\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI-jucDYC03Z",
        "outputId": "b5ace47c-dbca-41d4-99bb-59003a4140d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how many labels are available?\n",
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuD_VG7EDcrW",
        "outputId": "068561c8-75df-484b-a606-1679dfa6b1de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#what is the shape of the postage stamps that constitute the dataset?\n",
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFbX8xlEDzHh",
        "outputId": "caa702e9-4e7b-46ad-b5a5-357c4df3f8cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show the first input data object\n",
        "\n",
        "plt.imshow(x_train[0], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "wlAJPOVzD3Kn",
        "outputId": "01982cd3-6ba6-43b4-9de0-133681eae21c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c596d20aa70>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check how many possible values are in the target variable\n",
        "np.unique(y_train, return_counts=True)"
      ],
      "metadata": {
        "id": "EEBSFCPuEAyQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b44e5f5-e141-4eb6-d6fa-6f1dfc87066f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
              " array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check what is the minimum and maximum value and data type of the features dataset\n",
        "x_train.min(), x_train.max(), x_train.dtype"
      ],
      "metadata": {
        "id": "4tjUUsqOELhP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8934265-0b20-4795-975c-9fd6e355c3b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 255, dtype('uint8'))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scale the imput data so that it is min=0 and max=1 (min-max scaling) and that the values are floating point objects\n",
        "x_train = x_train/255.\n",
        "x_test = x_test/255.\n"
      ],
      "metadata": {
        "id": "O9c7pvCiEPBT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the shape should have not changed\n",
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojr_ateAElqV",
        "outputId": "54626f4e-6f91-438b-a50b-cb73135f3a81"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the number of pixels in the data is\n",
        "28*28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P9gsr1rGNvq",
        "outputId": "66ffc2ad-cbeb-44c9-f34c-1d3491908b63"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the first Artificial Neural Network\n",
        "solve the problem as a regression - see slides for the appropriate choices\n",
        "\n",
        "- use dense layers\n",
        "- choose the right number of neurons in output to solve a _regression_ problem\n",
        "- choose the right activation function on the last layer for a _regression_ problem\n",
        "- chose the right loss function for a _regression_ problem\n"
      ],
      "metadata": {
        "id": "RIQNmcwcn1li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# architecture hyperparametrs\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
        "# add 1 dense layer with 128 neurons and relu activation function\n",
        "# add 1 dropout layers dropping 20% of the connections\n",
        "# add 1 dense layer with 10 neurons\n",
        "# add the output  layer with 1\n",
        "# your code goes here\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(10))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "k0ais0jQEzz4",
        "outputId": "2779e939-66ad-439d-e17b-e531765011db"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m11\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,781\u001b[0m (397.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,781</span> (397.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,781\u001b[0m (397.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,781</span> (397.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TtClRvLcG4VV",
        "outputId": "b4d69c7e-da27-4c85-89ce-0bf57dbc88db"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training hyperparameter\n",
        "# choose the MeanSquaredError and Adam as the optimizer\n",
        "\n",
        "loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "metadata": {
        "id": "gjLqvxoJFTwH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train the model (did you make sure you are using GPUs??)\n",
        "model.compile(optimizer = optimizer, loss = loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "training_history = model.fit(x_train, y_train, epochs=500, validation_split=0.1)"
      ],
      "metadata": {
        "id": "cp73OULPH8aB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c0fe251-9782-496f-e5a3-12c02cc8e8ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1689 - loss: 0.4277 - val_accuracy: 0.1733 - val_loss: 0.7047\n",
            "Epoch 2/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1694 - loss: 0.4305 - val_accuracy: 0.1662 - val_loss: 0.6918\n",
            "Epoch 3/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1696 - loss: 0.4351 - val_accuracy: 0.1833 - val_loss: 0.6749\n",
            "Epoch 4/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1688 - loss: 0.4366 - val_accuracy: 0.1778 - val_loss: 0.6747\n",
            "Epoch 5/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1709 - loss: 0.4232 - val_accuracy: 0.1732 - val_loss: 0.6976\n",
            "Epoch 6/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1701 - loss: 0.4417 - val_accuracy: 0.1763 - val_loss: 0.6673\n",
            "Epoch 7/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1687 - loss: 0.4350 - val_accuracy: 0.1663 - val_loss: 0.6930\n",
            "Epoch 8/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1697 - loss: 0.4341 - val_accuracy: 0.1752 - val_loss: 0.6787\n",
            "Epoch 9/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1692 - loss: 0.4280 - val_accuracy: 0.1727 - val_loss: 0.6793\n",
            "Epoch 10/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1675 - loss: 0.4256 - val_accuracy: 0.1770 - val_loss: 0.6970\n",
            "Epoch 11/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1694 - loss: 0.4272 - val_accuracy: 0.1775 - val_loss: 0.6707\n",
            "Epoch 12/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1697 - loss: 0.4293 - val_accuracy: 0.1723 - val_loss: 0.6839\n",
            "Epoch 13/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1668 - loss: 0.4260 - val_accuracy: 0.1795 - val_loss: 0.6835\n",
            "Epoch 14/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1669 - loss: 0.4265 - val_accuracy: 0.1813 - val_loss: 0.6855\n",
            "Epoch 15/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1685 - loss: 0.4276 - val_accuracy: 0.1740 - val_loss: 0.6724\n",
            "Epoch 16/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1675 - loss: 0.4241 - val_accuracy: 0.1742 - val_loss: 0.6791\n",
            "Epoch 17/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1688 - loss: 0.4239 - val_accuracy: 0.1748 - val_loss: 0.6791\n",
            "Epoch 18/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1681 - loss: 0.4199 - val_accuracy: 0.1807 - val_loss: 0.6742\n",
            "Epoch 19/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1679 - loss: 0.4253 - val_accuracy: 0.1817 - val_loss: 0.6902\n",
            "Epoch 20/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1696 - loss: 0.4270 - val_accuracy: 0.1765 - val_loss: 0.6756\n",
            "Epoch 21/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1690 - loss: 0.4287 - val_accuracy: 0.1755 - val_loss: 0.6993\n",
            "Epoch 22/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1695 - loss: 0.4259 - val_accuracy: 0.1757 - val_loss: 0.6737\n",
            "Epoch 23/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1694 - loss: 0.4296 - val_accuracy: 0.1708 - val_loss: 0.6833\n",
            "Epoch 24/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1687 - loss: 0.4277 - val_accuracy: 0.1717 - val_loss: 0.6874\n",
            "Epoch 25/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1692 - loss: 0.4205 - val_accuracy: 0.1727 - val_loss: 0.6821\n",
            "Epoch 26/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1670 - loss: 0.4200 - val_accuracy: 0.1808 - val_loss: 0.6934\n",
            "Epoch 27/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1672 - loss: 0.4301 - val_accuracy: 0.1825 - val_loss: 0.6928\n",
            "Epoch 28/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1689 - loss: 0.4208 - val_accuracy: 0.1790 - val_loss: 0.6791\n",
            "Epoch 29/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1684 - loss: 0.4256 - val_accuracy: 0.1785 - val_loss: 0.6774\n",
            "Epoch 30/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1711 - loss: 0.4260 - val_accuracy: 0.1730 - val_loss: 0.6771\n",
            "Epoch 31/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1670 - loss: 0.4122 - val_accuracy: 0.1730 - val_loss: 0.6812\n",
            "Epoch 32/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1675 - loss: 0.4304 - val_accuracy: 0.1735 - val_loss: 0.6880\n",
            "Epoch 33/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1674 - loss: 0.4191 - val_accuracy: 0.1772 - val_loss: 0.6840\n",
            "Epoch 34/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1691 - loss: 0.4312 - val_accuracy: 0.1797 - val_loss: 0.6840\n",
            "Epoch 35/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1675 - loss: 0.4235 - val_accuracy: 0.1800 - val_loss: 0.6809\n",
            "Epoch 36/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1705 - loss: 0.4171 - val_accuracy: 0.1743 - val_loss: 0.6860\n",
            "Epoch 37/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1700 - loss: 0.4316 - val_accuracy: 0.1785 - val_loss: 0.6907\n",
            "Epoch 38/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1670 - loss: 0.4219 - val_accuracy: 0.1745 - val_loss: 0.6832\n",
            "Epoch 39/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1716 - loss: 0.4259 - val_accuracy: 0.1727 - val_loss: 0.7073\n",
            "Epoch 40/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1685 - loss: 0.4204 - val_accuracy: 0.1690 - val_loss: 0.6941\n",
            "Epoch 41/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1716 - loss: 0.4220 - val_accuracy: 0.1645 - val_loss: 0.6943\n",
            "Epoch 42/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1703 - loss: 0.4219 - val_accuracy: 0.1827 - val_loss: 0.6740\n",
            "Epoch 43/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1680 - loss: 0.4217 - val_accuracy: 0.1755 - val_loss: 0.6881\n",
            "Epoch 44/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1698 - loss: 0.4149 - val_accuracy: 0.1832 - val_loss: 0.6737\n",
            "Epoch 45/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1679 - loss: 0.4171 - val_accuracy: 0.1783 - val_loss: 0.6858\n",
            "Epoch 46/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1686 - loss: 0.4111 - val_accuracy: 0.1823 - val_loss: 0.6809\n",
            "Epoch 47/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1706 - loss: 0.4201 - val_accuracy: 0.1720 - val_loss: 0.6973\n",
            "Epoch 48/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1714 - loss: 0.4275 - val_accuracy: 0.1853 - val_loss: 0.6870\n",
            "Epoch 49/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1678 - loss: 0.4353 - val_accuracy: 0.1697 - val_loss: 0.6953\n",
            "Epoch 50/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1669 - loss: 0.4222 - val_accuracy: 0.1732 - val_loss: 0.6858\n",
            "Epoch 51/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1682 - loss: 0.4153 - val_accuracy: 0.1738 - val_loss: 0.6943\n",
            "Epoch 52/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1712 - loss: 0.4201 - val_accuracy: 0.1735 - val_loss: 0.6936\n",
            "Epoch 53/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1682 - loss: 0.4146 - val_accuracy: 0.1783 - val_loss: 0.6950\n",
            "Epoch 54/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1688 - loss: 0.4234 - val_accuracy: 0.1755 - val_loss: 0.6891\n",
            "Epoch 55/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1700 - loss: 0.4181 - val_accuracy: 0.1755 - val_loss: 0.6869\n",
            "Epoch 56/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1704 - loss: 0.4193 - val_accuracy: 0.1782 - val_loss: 0.6896\n",
            "Epoch 57/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1701 - loss: 0.4178 - val_accuracy: 0.1782 - val_loss: 0.6824\n",
            "Epoch 58/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1672 - loss: 0.4121 - val_accuracy: 0.1782 - val_loss: 0.6830\n",
            "Epoch 59/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1679 - loss: 0.4123 - val_accuracy: 0.1768 - val_loss: 0.6911\n",
            "Epoch 60/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1695 - loss: 0.4183 - val_accuracy: 0.1812 - val_loss: 0.6921\n",
            "Epoch 61/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1720 - loss: 0.4171 - val_accuracy: 0.1755 - val_loss: 0.6875\n",
            "Epoch 62/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1706 - loss: 0.4151 - val_accuracy: 0.1707 - val_loss: 0.6843\n",
            "Epoch 63/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1683 - loss: 0.4079 - val_accuracy: 0.1795 - val_loss: 0.6856\n",
            "Epoch 64/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1682 - loss: 0.4138 - val_accuracy: 0.1760 - val_loss: 0.6945\n",
            "Epoch 65/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1718 - loss: 0.4131 - val_accuracy: 0.1798 - val_loss: 0.6867\n",
            "Epoch 66/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1659 - loss: 0.4180 - val_accuracy: 0.1640 - val_loss: 0.6973\n",
            "Epoch 67/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1703 - loss: 0.4181 - val_accuracy: 0.1767 - val_loss: 0.6921\n",
            "Epoch 68/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1702 - loss: 0.4077 - val_accuracy: 0.1808 - val_loss: 0.6871\n",
            "Epoch 69/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1710 - loss: 0.4116 - val_accuracy: 0.1790 - val_loss: 0.6900\n",
            "Epoch 70/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1678 - loss: 0.4074 - val_accuracy: 0.1725 - val_loss: 0.6883\n",
            "Epoch 71/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1698 - loss: 0.4191 - val_accuracy: 0.1767 - val_loss: 0.6918\n",
            "Epoch 72/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1695 - loss: 0.4162 - val_accuracy: 0.1663 - val_loss: 0.6952\n",
            "Epoch 73/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1678 - loss: 0.4141 - val_accuracy: 0.1812 - val_loss: 0.6794\n",
            "Epoch 74/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1698 - loss: 0.4057 - val_accuracy: 0.1705 - val_loss: 0.7034\n",
            "Epoch 75/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1682 - loss: 0.4189 - val_accuracy: 0.1598 - val_loss: 0.7080\n",
            "Epoch 76/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1697 - loss: 0.4139 - val_accuracy: 0.1672 - val_loss: 0.6909\n",
            "Epoch 77/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1692 - loss: 0.4001 - val_accuracy: 0.1823 - val_loss: 0.6876\n",
            "Epoch 78/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1708 - loss: 0.4143 - val_accuracy: 0.1792 - val_loss: 0.6750\n",
            "Epoch 79/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1710 - loss: 0.4058 - val_accuracy: 0.1800 - val_loss: 0.6781\n",
            "Epoch 80/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1703 - loss: 0.4207 - val_accuracy: 0.1800 - val_loss: 0.6806\n",
            "Epoch 81/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1694 - loss: 0.4094 - val_accuracy: 0.1780 - val_loss: 0.6998\n",
            "Epoch 82/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1700 - loss: 0.4160 - val_accuracy: 0.1810 - val_loss: 0.6894\n",
            "Epoch 83/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1701 - loss: 0.4156 - val_accuracy: 0.1782 - val_loss: 0.6844\n",
            "Epoch 84/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1681 - loss: 0.4230 - val_accuracy: 0.1765 - val_loss: 0.6971\n",
            "Epoch 85/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1691 - loss: 0.4136 - val_accuracy: 0.1690 - val_loss: 0.6997\n",
            "Epoch 86/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1690 - loss: 0.4130 - val_accuracy: 0.1757 - val_loss: 0.6938\n",
            "Epoch 87/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1686 - loss: 0.4100 - val_accuracy: 0.1828 - val_loss: 0.6869\n",
            "Epoch 88/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1710 - loss: 0.4035 - val_accuracy: 0.1743 - val_loss: 0.6835\n",
            "Epoch 89/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1680 - loss: 0.4092 - val_accuracy: 0.1793 - val_loss: 0.6857\n",
            "Epoch 90/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1692 - loss: 0.4105 - val_accuracy: 0.1745 - val_loss: 0.6851\n",
            "Epoch 91/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1716 - loss: 0.4129 - val_accuracy: 0.1833 - val_loss: 0.7029\n",
            "Epoch 92/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1669 - loss: 0.4048 - val_accuracy: 0.1778 - val_loss: 0.6933\n",
            "Epoch 93/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1726 - loss: 0.4061 - val_accuracy: 0.1788 - val_loss: 0.7015\n",
            "Epoch 94/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1716 - loss: 0.4048 - val_accuracy: 0.1812 - val_loss: 0.7271\n",
            "Epoch 95/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1708 - loss: 0.4133 - val_accuracy: 0.1818 - val_loss: 0.6928\n",
            "Epoch 96/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1702 - loss: 0.4151 - val_accuracy: 0.1715 - val_loss: 0.6947\n",
            "Epoch 97/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1701 - loss: 0.4003 - val_accuracy: 0.1770 - val_loss: 0.6921\n",
            "Epoch 98/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1720 - loss: 0.4063 - val_accuracy: 0.1695 - val_loss: 0.6952\n",
            "Epoch 99/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1668 - loss: 0.4188 - val_accuracy: 0.1772 - val_loss: 0.7022\n",
            "Epoch 100/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1702 - loss: 0.4111 - val_accuracy: 0.1735 - val_loss: 0.6969\n",
            "Epoch 101/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1695 - loss: 0.4082 - val_accuracy: 0.1808 - val_loss: 0.6855\n",
            "Epoch 102/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1701 - loss: 0.4088 - val_accuracy: 0.1803 - val_loss: 0.6904\n",
            "Epoch 103/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1697 - loss: 0.4110 - val_accuracy: 0.1838 - val_loss: 0.6976\n",
            "Epoch 104/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1733 - loss: 0.4093 - val_accuracy: 0.1673 - val_loss: 0.6960\n",
            "Epoch 105/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1700 - loss: 0.4082 - val_accuracy: 0.1693 - val_loss: 0.6832\n",
            "Epoch 106/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1713 - loss: 0.4078 - val_accuracy: 0.1710 - val_loss: 0.7037\n",
            "Epoch 107/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1703 - loss: 0.4090 - val_accuracy: 0.1705 - val_loss: 0.6976\n",
            "Epoch 108/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1700 - loss: 0.4015 - val_accuracy: 0.1722 - val_loss: 0.6933\n",
            "Epoch 109/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1677 - loss: 0.4023 - val_accuracy: 0.1782 - val_loss: 0.6915\n",
            "Epoch 110/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1702 - loss: 0.4083 - val_accuracy: 0.1757 - val_loss: 0.6874\n",
            "Epoch 111/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1697 - loss: 0.4050 - val_accuracy: 0.1848 - val_loss: 0.6850\n",
            "Epoch 112/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1707 - loss: 0.4038 - val_accuracy: 0.1807 - val_loss: 0.6833\n",
            "Epoch 113/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1716 - loss: 0.4039 - val_accuracy: 0.1720 - val_loss: 0.6914\n",
            "Epoch 114/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1736 - loss: 0.3972 - val_accuracy: 0.1783 - val_loss: 0.6943\n",
            "Epoch 115/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1721 - loss: 0.4146 - val_accuracy: 0.1810 - val_loss: 0.7021\n",
            "Epoch 116/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1686 - loss: 0.4126 - val_accuracy: 0.1755 - val_loss: 0.6960\n",
            "Epoch 117/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1704 - loss: 0.4058 - val_accuracy: 0.1747 - val_loss: 0.6821\n",
            "Epoch 118/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1705 - loss: 0.4018 - val_accuracy: 0.1765 - val_loss: 0.6876\n",
            "Epoch 119/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1701 - loss: 0.4046 - val_accuracy: 0.1770 - val_loss: 0.6903\n",
            "Epoch 120/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1691 - loss: 0.4041 - val_accuracy: 0.1712 - val_loss: 0.7182\n",
            "Epoch 121/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1705 - loss: 0.4065 - val_accuracy: 0.1840 - val_loss: 0.6910\n",
            "Epoch 122/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1675 - loss: 0.4101 - val_accuracy: 0.1775 - val_loss: 0.6924\n",
            "Epoch 123/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1658 - loss: 0.4038 - val_accuracy: 0.1745 - val_loss: 0.7091\n",
            "Epoch 124/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1706 - loss: 0.4004 - val_accuracy: 0.1668 - val_loss: 0.6891\n",
            "Epoch 125/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1723 - loss: 0.4010 - val_accuracy: 0.1757 - val_loss: 0.6869\n",
            "Epoch 126/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1685 - loss: 0.4086 - val_accuracy: 0.1738 - val_loss: 0.6932\n",
            "Epoch 127/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.1688 - loss: 0.3984 - val_accuracy: 0.1770 - val_loss: 0.6911\n",
            "Epoch 128/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1733 - loss: 0.3909 - val_accuracy: 0.1785 - val_loss: 0.6878\n",
            "Epoch 129/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1737 - loss: 0.4029 - val_accuracy: 0.1772 - val_loss: 0.6925\n",
            "Epoch 130/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1703 - loss: 0.4130 - val_accuracy: 0.1777 - val_loss: 0.6923\n",
            "Epoch 131/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1676 - loss: 0.4011 - val_accuracy: 0.1737 - val_loss: 0.7087\n",
            "Epoch 132/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1688 - loss: 0.4078 - val_accuracy: 0.1768 - val_loss: 0.6974\n",
            "Epoch 133/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1716 - loss: 0.4004 - val_accuracy: 0.1670 - val_loss: 0.7004\n",
            "Epoch 134/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1693 - loss: 0.4084 - val_accuracy: 0.1767 - val_loss: 0.7036\n",
            "Epoch 135/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1703 - loss: 0.3969 - val_accuracy: 0.1750 - val_loss: 0.6964\n",
            "Epoch 136/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1725 - loss: 0.3925 - val_accuracy: 0.1808 - val_loss: 0.6981\n",
            "Epoch 137/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1716 - loss: 0.3868 - val_accuracy: 0.1757 - val_loss: 0.6951\n",
            "Epoch 138/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1694 - loss: 0.3945 - val_accuracy: 0.1787 - val_loss: 0.7420\n",
            "Epoch 139/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1692 - loss: 0.3997 - val_accuracy: 0.1802 - val_loss: 0.7015\n",
            "Epoch 140/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1688 - loss: 0.4114 - val_accuracy: 0.1807 - val_loss: 0.6962\n",
            "Epoch 141/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1725 - loss: 0.4034 - val_accuracy: 0.1783 - val_loss: 0.6956\n",
            "Epoch 142/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1706 - loss: 0.4023 - val_accuracy: 0.1667 - val_loss: 0.7086\n",
            "Epoch 143/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1699 - loss: 0.3920 - val_accuracy: 0.1752 - val_loss: 0.6994\n",
            "Epoch 144/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1714 - loss: 0.3955 - val_accuracy: 0.1728 - val_loss: 0.7126\n",
            "Epoch 145/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1693 - loss: 0.4018 - val_accuracy: 0.1802 - val_loss: 0.6967\n",
            "Epoch 146/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1705 - loss: 0.3989 - val_accuracy: 0.1775 - val_loss: 0.6966\n",
            "Epoch 147/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1733 - loss: 0.4031 - val_accuracy: 0.1803 - val_loss: 0.7078\n",
            "Epoch 148/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1689 - loss: 0.3879 - val_accuracy: 0.1697 - val_loss: 0.7157\n",
            "Epoch 149/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1709 - loss: 0.4010 - val_accuracy: 0.1732 - val_loss: 0.7027\n",
            "Epoch 150/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1685 - loss: 0.3975 - val_accuracy: 0.1782 - val_loss: 0.7095\n",
            "Epoch 151/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1720 - loss: 0.4036 - val_accuracy: 0.1827 - val_loss: 0.6973\n",
            "Epoch 152/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1735 - loss: 0.4024 - val_accuracy: 0.1732 - val_loss: 0.6962\n",
            "Epoch 153/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1719 - loss: 0.4051 - val_accuracy: 0.1728 - val_loss: 0.7034\n",
            "Epoch 154/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1685 - loss: 0.3961 - val_accuracy: 0.1772 - val_loss: 0.7017\n",
            "Epoch 155/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1729 - loss: 0.3968 - val_accuracy: 0.1762 - val_loss: 0.6994\n",
            "Epoch 156/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1672 - loss: 0.3894 - val_accuracy: 0.1833 - val_loss: 0.7136\n",
            "Epoch 157/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1709 - loss: 0.4030 - val_accuracy: 0.1743 - val_loss: 0.7045\n",
            "Epoch 158/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1724 - loss: 0.4038 - val_accuracy: 0.1732 - val_loss: 0.6965\n",
            "Epoch 159/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1714 - loss: 0.4007 - val_accuracy: 0.1758 - val_loss: 0.7044\n",
            "Epoch 160/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1685 - loss: 0.3918 - val_accuracy: 0.1773 - val_loss: 0.7095\n",
            "Epoch 161/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1717 - loss: 0.3967 - val_accuracy: 0.1742 - val_loss: 0.7005\n",
            "Epoch 162/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1723 - loss: 0.3971 - val_accuracy: 0.1775 - val_loss: 0.7047\n",
            "Epoch 163/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1681 - loss: 0.3982 - val_accuracy: 0.1775 - val_loss: 0.6900\n",
            "Epoch 164/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1720 - loss: 0.3802 - val_accuracy: 0.1775 - val_loss: 0.7077\n",
            "Epoch 165/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1701 - loss: 0.4022 - val_accuracy: 0.1795 - val_loss: 0.6991\n",
            "Epoch 166/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1693 - loss: 0.3947 - val_accuracy: 0.1792 - val_loss: 0.7114\n",
            "Epoch 167/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1709 - loss: 0.3905 - val_accuracy: 0.1690 - val_loss: 0.7016\n",
            "Epoch 168/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1673 - loss: 0.4040 - val_accuracy: 0.1780 - val_loss: 0.7160\n",
            "Epoch 169/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1699 - loss: 0.3981 - val_accuracy: 0.1868 - val_loss: 0.7081\n",
            "Epoch 170/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1702 - loss: 0.3875 - val_accuracy: 0.1790 - val_loss: 0.7031\n",
            "Epoch 171/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1727 - loss: 0.3933 - val_accuracy: 0.1722 - val_loss: 0.6931\n",
            "Epoch 172/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1701 - loss: 0.3991 - val_accuracy: 0.1730 - val_loss: 0.7017\n",
            "Epoch 173/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1684 - loss: 0.3980 - val_accuracy: 0.1788 - val_loss: 0.6962\n",
            "Epoch 174/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1699 - loss: 0.3962 - val_accuracy: 0.1740 - val_loss: 0.7071\n",
            "Epoch 175/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1720 - loss: 0.3901 - val_accuracy: 0.1735 - val_loss: 0.7226\n",
            "Epoch 176/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1714 - loss: 0.4028 - val_accuracy: 0.1773 - val_loss: 0.6995\n",
            "Epoch 177/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1671 - loss: 0.3950 - val_accuracy: 0.1773 - val_loss: 0.7056\n",
            "Epoch 178/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1683 - loss: 0.3981 - val_accuracy: 0.1735 - val_loss: 0.6985\n",
            "Epoch 179/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1689 - loss: 0.3986 - val_accuracy: 0.1788 - val_loss: 0.7047\n",
            "Epoch 180/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1690 - loss: 0.4067 - val_accuracy: 0.1807 - val_loss: 0.6990\n",
            "Epoch 181/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1731 - loss: 0.3876 - val_accuracy: 0.1722 - val_loss: 0.7048\n",
            "Epoch 182/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1727 - loss: 0.3909 - val_accuracy: 0.1820 - val_loss: 0.7106\n",
            "Epoch 183/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1718 - loss: 0.3917 - val_accuracy: 0.1797 - val_loss: 0.6890\n",
            "Epoch 184/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1706 - loss: 0.3914 - val_accuracy: 0.1758 - val_loss: 0.7098\n",
            "Epoch 185/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1710 - loss: 0.3950 - val_accuracy: 0.1782 - val_loss: 0.6927\n",
            "Epoch 186/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1720 - loss: 0.3942 - val_accuracy: 0.1792 - val_loss: 0.6931\n",
            "Epoch 187/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1712 - loss: 0.3837 - val_accuracy: 0.1643 - val_loss: 0.7102\n",
            "Epoch 188/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1707 - loss: 0.3950 - val_accuracy: 0.1833 - val_loss: 0.7004\n",
            "Epoch 189/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1717 - loss: 0.3820 - val_accuracy: 0.1790 - val_loss: 0.6999\n",
            "Epoch 190/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1738 - loss: 0.3902 - val_accuracy: 0.1772 - val_loss: 0.7006\n",
            "Epoch 191/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1691 - loss: 0.4016 - val_accuracy: 0.1678 - val_loss: 0.7018\n",
            "Epoch 192/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1706 - loss: 0.3909 - val_accuracy: 0.1738 - val_loss: 0.6951\n",
            "Epoch 193/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1665 - loss: 0.3970 - val_accuracy: 0.1755 - val_loss: 0.7025\n",
            "Epoch 194/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1711 - loss: 0.3935 - val_accuracy: 0.1695 - val_loss: 0.6960\n",
            "Epoch 195/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1716 - loss: 0.3978 - val_accuracy: 0.1775 - val_loss: 0.7047\n",
            "Epoch 196/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1703 - loss: 0.3849 - val_accuracy: 0.1692 - val_loss: 0.7097\n",
            "Epoch 197/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1684 - loss: 0.3959 - val_accuracy: 0.1752 - val_loss: 0.7118\n",
            "Epoch 198/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1713 - loss: 0.3913 - val_accuracy: 0.1798 - val_loss: 0.6978\n",
            "Epoch 199/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1712 - loss: 0.3973 - val_accuracy: 0.1715 - val_loss: 0.7058\n",
            "Epoch 200/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1753 - loss: 0.3974 - val_accuracy: 0.1827 - val_loss: 0.6929\n",
            "Epoch 201/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1710 - loss: 0.3866 - val_accuracy: 0.1762 - val_loss: 0.6860\n",
            "Epoch 202/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1729 - loss: 0.3894 - val_accuracy: 0.1792 - val_loss: 0.6924\n",
            "Epoch 203/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1705 - loss: 0.3829 - val_accuracy: 0.1808 - val_loss: 0.6983\n",
            "Epoch 204/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1707 - loss: 0.3870 - val_accuracy: 0.1810 - val_loss: 0.6994\n",
            "Epoch 205/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1689 - loss: 0.3975 - val_accuracy: 0.1722 - val_loss: 0.6922\n",
            "Epoch 206/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1710 - loss: 0.3967 - val_accuracy: 0.1788 - val_loss: 0.7046\n",
            "Epoch 207/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1698 - loss: 0.3841 - val_accuracy: 0.1785 - val_loss: 0.6926\n",
            "Epoch 208/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1708 - loss: 0.3870 - val_accuracy: 0.1738 - val_loss: 0.7087\n",
            "Epoch 209/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1710 - loss: 0.3848 - val_accuracy: 0.1660 - val_loss: 0.7057\n",
            "Epoch 210/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1700 - loss: 0.3938 - val_accuracy: 0.1762 - val_loss: 0.7147\n",
            "Epoch 211/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1702 - loss: 0.3835 - val_accuracy: 0.1732 - val_loss: 0.7111\n",
            "Epoch 212/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1715 - loss: 0.3861 - val_accuracy: 0.1758 - val_loss: 0.7032\n",
            "Epoch 213/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1735 - loss: 0.3858 - val_accuracy: 0.1818 - val_loss: 0.6978\n",
            "Epoch 214/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1721 - loss: 0.3874 - val_accuracy: 0.1690 - val_loss: 0.7003\n",
            "Epoch 215/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1694 - loss: 0.3861 - val_accuracy: 0.1833 - val_loss: 0.7063\n",
            "Epoch 216/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1712 - loss: 0.3921 - val_accuracy: 0.1805 - val_loss: 0.7015\n",
            "Epoch 217/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1702 - loss: 0.3977 - val_accuracy: 0.1762 - val_loss: 0.6964\n",
            "Epoch 218/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1709 - loss: 0.3929 - val_accuracy: 0.1708 - val_loss: 0.7321\n",
            "Epoch 219/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1735 - loss: 0.3991 - val_accuracy: 0.1778 - val_loss: 0.7005\n",
            "Epoch 220/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1746 - loss: 0.3817 - val_accuracy: 0.1783 - val_loss: 0.7021\n",
            "Epoch 221/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1713 - loss: 0.3840 - val_accuracy: 0.1773 - val_loss: 0.7024\n",
            "Epoch 222/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1719 - loss: 0.3911 - val_accuracy: 0.1753 - val_loss: 0.7049\n",
            "Epoch 223/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1694 - loss: 0.3937 - val_accuracy: 0.1637 - val_loss: 0.6991\n",
            "Epoch 224/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1722 - loss: 0.3839 - val_accuracy: 0.1762 - val_loss: 0.7025\n",
            "Epoch 225/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1718 - loss: 0.3956 - val_accuracy: 0.1817 - val_loss: 0.7021\n",
            "Epoch 226/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1692 - loss: 0.3934 - val_accuracy: 0.1817 - val_loss: 0.7075\n",
            "Epoch 227/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1723 - loss: 0.3881 - val_accuracy: 0.1678 - val_loss: 0.7029\n",
            "Epoch 228/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1706 - loss: 0.3901 - val_accuracy: 0.1683 - val_loss: 0.7134\n",
            "Epoch 229/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1720 - loss: 0.3858 - val_accuracy: 0.1783 - val_loss: 0.6978\n",
            "Epoch 230/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1723 - loss: 0.3874 - val_accuracy: 0.1722 - val_loss: 0.6986\n",
            "Epoch 231/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1694 - loss: 0.3928 - val_accuracy: 0.1690 - val_loss: 0.7173\n",
            "Epoch 232/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1720 - loss: 0.3888 - val_accuracy: 0.1770 - val_loss: 0.7033\n",
            "Epoch 233/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1722 - loss: 0.3869 - val_accuracy: 0.1745 - val_loss: 0.7086\n",
            "Epoch 234/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1699 - loss: 0.3818 - val_accuracy: 0.1810 - val_loss: 0.7021\n",
            "Epoch 235/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1690 - loss: 0.3928 - val_accuracy: 0.1793 - val_loss: 0.7039\n",
            "Epoch 236/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1726 - loss: 0.3847 - val_accuracy: 0.1722 - val_loss: 0.7124\n",
            "Epoch 237/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1730 - loss: 0.3883 - val_accuracy: 0.1788 - val_loss: 0.6993\n",
            "Epoch 238/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1694 - loss: 0.3839 - val_accuracy: 0.1798 - val_loss: 0.7026\n",
            "Epoch 239/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1704 - loss: 0.3886 - val_accuracy: 0.1722 - val_loss: 0.7117\n",
            "Epoch 240/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1726 - loss: 0.3863 - val_accuracy: 0.1683 - val_loss: 0.6991\n",
            "Epoch 241/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1731 - loss: 0.3882 - val_accuracy: 0.1688 - val_loss: 0.7046\n",
            "Epoch 242/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1711 - loss: 0.3836 - val_accuracy: 0.1767 - val_loss: 0.7089\n",
            "Epoch 243/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1725 - loss: 0.3860 - val_accuracy: 0.1747 - val_loss: 0.7071\n",
            "Epoch 244/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1699 - loss: 0.3927 - val_accuracy: 0.1790 - val_loss: 0.6962\n",
            "Epoch 245/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1726 - loss: 0.3774 - val_accuracy: 0.1772 - val_loss: 0.7059\n",
            "Epoch 246/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1717 - loss: 0.3921 - val_accuracy: 0.1838 - val_loss: 0.7170\n",
            "Epoch 247/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1692 - loss: 0.3962 - val_accuracy: 0.1750 - val_loss: 0.7020\n",
            "Epoch 248/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1701 - loss: 0.3835 - val_accuracy: 0.1672 - val_loss: 0.7066\n",
            "Epoch 249/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1710 - loss: 0.3806 - val_accuracy: 0.1798 - val_loss: 0.7012\n",
            "Epoch 250/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1706 - loss: 0.3884 - val_accuracy: 0.1645 - val_loss: 0.7405\n",
            "Epoch 251/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1724 - loss: 0.3821 - val_accuracy: 0.1760 - val_loss: 0.7086\n",
            "Epoch 252/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1722 - loss: 0.3836 - val_accuracy: 0.1835 - val_loss: 0.7119\n",
            "Epoch 253/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1708 - loss: 0.3872 - val_accuracy: 0.1743 - val_loss: 0.7050\n",
            "Epoch 254/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1725 - loss: 0.3829 - val_accuracy: 0.1798 - val_loss: 0.7001\n",
            "Epoch 255/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1717 - loss: 0.3784 - val_accuracy: 0.1732 - val_loss: 0.7295\n",
            "Epoch 256/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1727 - loss: 0.3889 - val_accuracy: 0.1778 - val_loss: 0.7101\n",
            "Epoch 257/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1699 - loss: 0.3848 - val_accuracy: 0.1747 - val_loss: 0.7022\n",
            "Epoch 258/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1705 - loss: 0.3896 - val_accuracy: 0.1807 - val_loss: 0.7026\n",
            "Epoch 259/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1751 - loss: 0.3905 - val_accuracy: 0.1798 - val_loss: 0.7008\n",
            "Epoch 260/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1724 - loss: 0.3813 - val_accuracy: 0.1712 - val_loss: 0.7210\n",
            "Epoch 261/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1701 - loss: 0.3817 - val_accuracy: 0.1747 - val_loss: 0.7187\n",
            "Epoch 262/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1696 - loss: 0.3899 - val_accuracy: 0.1650 - val_loss: 0.7178\n",
            "Epoch 263/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1697 - loss: 0.3953 - val_accuracy: 0.1685 - val_loss: 0.7066\n",
            "Epoch 264/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1727 - loss: 0.3847 - val_accuracy: 0.1773 - val_loss: 0.7086\n",
            "Epoch 265/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1680 - loss: 0.3889 - val_accuracy: 0.1815 - val_loss: 0.7148\n",
            "Epoch 266/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1727 - loss: 0.3863 - val_accuracy: 0.1758 - val_loss: 0.7170\n",
            "Epoch 267/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1731 - loss: 0.3914 - val_accuracy: 0.1653 - val_loss: 0.7205\n",
            "Epoch 268/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1716 - loss: 0.3884 - val_accuracy: 0.1822 - val_loss: 0.7078\n",
            "Epoch 269/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1716 - loss: 0.3932 - val_accuracy: 0.1800 - val_loss: 0.7043\n",
            "Epoch 270/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1730 - loss: 0.3879 - val_accuracy: 0.1762 - val_loss: 0.7089\n",
            "Epoch 271/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1684 - loss: 0.3864 - val_accuracy: 0.1782 - val_loss: 0.6962\n",
            "Epoch 272/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1728 - loss: 0.3809 - val_accuracy: 0.1778 - val_loss: 0.7092\n",
            "Epoch 273/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1709 - loss: 0.3816 - val_accuracy: 0.1800 - val_loss: 0.7069\n",
            "Epoch 274/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1704 - loss: 0.3887 - val_accuracy: 0.1758 - val_loss: 0.7223\n",
            "Epoch 275/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1730 - loss: 0.3870 - val_accuracy: 0.1740 - val_loss: 0.7102\n",
            "Epoch 276/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1711 - loss: 0.3887 - val_accuracy: 0.1763 - val_loss: 0.7285\n",
            "Epoch 277/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1726 - loss: 0.3864 - val_accuracy: 0.1792 - val_loss: 0.7144\n",
            "Epoch 278/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1731 - loss: 0.3885 - val_accuracy: 0.1582 - val_loss: 0.7203\n",
            "Epoch 279/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1705 - loss: 0.3830 - val_accuracy: 0.1805 - val_loss: 0.7210\n",
            "Epoch 280/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1720 - loss: 0.3864 - val_accuracy: 0.1700 - val_loss: 0.7146\n",
            "Epoch 281/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1697 - loss: 0.3896 - val_accuracy: 0.1827 - val_loss: 0.7111\n",
            "Epoch 282/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1732 - loss: 0.3876 - val_accuracy: 0.1787 - val_loss: 0.7021\n",
            "Epoch 283/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1745 - loss: 0.3797 - val_accuracy: 0.1760 - val_loss: 0.7141\n",
            "Epoch 284/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1742 - loss: 0.3803 - val_accuracy: 0.1813 - val_loss: 0.7062\n",
            "Epoch 285/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1720 - loss: 0.3789 - val_accuracy: 0.1803 - val_loss: 0.7207\n",
            "Epoch 286/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1712 - loss: 0.3758 - val_accuracy: 0.1713 - val_loss: 0.7046\n",
            "Epoch 287/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1709 - loss: 0.3806 - val_accuracy: 0.1807 - val_loss: 0.7069\n",
            "Epoch 288/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1708 - loss: 0.3962 - val_accuracy: 0.1710 - val_loss: 0.7108\n",
            "Epoch 289/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1721 - loss: 0.3775 - val_accuracy: 0.1778 - val_loss: 0.7104\n",
            "Epoch 290/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1727 - loss: 0.3890 - val_accuracy: 0.1735 - val_loss: 0.7151\n",
            "Epoch 291/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1726 - loss: 0.3805 - val_accuracy: 0.1705 - val_loss: 0.7155\n",
            "Epoch 292/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1735 - loss: 0.3816 - val_accuracy: 0.1705 - val_loss: 0.7139\n",
            "Epoch 293/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1736 - loss: 0.3840 - val_accuracy: 0.1782 - val_loss: 0.7177\n",
            "Epoch 294/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1703 - loss: 0.3829 - val_accuracy: 0.1733 - val_loss: 0.7072\n",
            "Epoch 295/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1707 - loss: 0.3855 - val_accuracy: 0.1740 - val_loss: 0.7117\n",
            "Epoch 296/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1689 - loss: 0.3906 - val_accuracy: 0.1703 - val_loss: 0.7109\n",
            "Epoch 297/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1711 - loss: 0.3797 - val_accuracy: 0.1838 - val_loss: 0.7153\n",
            "Epoch 298/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1709 - loss: 0.3799 - val_accuracy: 0.1777 - val_loss: 0.7118\n",
            "Epoch 299/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1692 - loss: 0.3884 - val_accuracy: 0.1750 - val_loss: 0.7143\n",
            "Epoch 300/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1750 - loss: 0.3844 - val_accuracy: 0.1793 - val_loss: 0.7091\n",
            "Epoch 301/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1729 - loss: 0.3772 - val_accuracy: 0.1770 - val_loss: 0.7110\n",
            "Epoch 302/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1669 - loss: 0.3808 - val_accuracy: 0.1798 - val_loss: 0.7146\n",
            "Epoch 303/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1725 - loss: 0.3819 - val_accuracy: 0.1777 - val_loss: 0.7114\n",
            "Epoch 304/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1725 - loss: 0.3817 - val_accuracy: 0.1817 - val_loss: 0.7326\n",
            "Epoch 305/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1691 - loss: 0.3889 - val_accuracy: 0.1787 - val_loss: 0.7111\n",
            "Epoch 306/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1725 - loss: 0.3868 - val_accuracy: 0.1783 - val_loss: 0.7154\n",
            "Epoch 307/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1714 - loss: 0.3751 - val_accuracy: 0.1790 - val_loss: 0.7144\n",
            "Epoch 308/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1731 - loss: 0.3837 - val_accuracy: 0.1810 - val_loss: 0.7043\n",
            "Epoch 309/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1739 - loss: 0.3764 - val_accuracy: 0.1787 - val_loss: 0.7085\n",
            "Epoch 310/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1705 - loss: 0.3743 - val_accuracy: 0.1745 - val_loss: 0.7134\n",
            "Epoch 311/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1721 - loss: 0.3823 - val_accuracy: 0.1682 - val_loss: 0.7133\n",
            "Epoch 312/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1714 - loss: 0.3795 - val_accuracy: 0.1670 - val_loss: 0.7151\n",
            "Epoch 313/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1702 - loss: 0.3858 - val_accuracy: 0.1783 - val_loss: 0.7128\n",
            "Epoch 314/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1726 - loss: 0.3822 - val_accuracy: 0.1813 - val_loss: 0.7103\n",
            "Epoch 315/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1722 - loss: 0.3888 - val_accuracy: 0.1783 - val_loss: 0.7103\n",
            "Epoch 316/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1692 - loss: 0.3826 - val_accuracy: 0.1702 - val_loss: 0.7209\n",
            "Epoch 317/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1732 - loss: 0.3784 - val_accuracy: 0.1762 - val_loss: 0.7162\n",
            "Epoch 318/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1718 - loss: 0.3874 - val_accuracy: 0.1747 - val_loss: 0.7221\n",
            "Epoch 319/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1664 - loss: 0.3756 - val_accuracy: 0.1603 - val_loss: 0.7205\n",
            "Epoch 320/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1709 - loss: 0.3783 - val_accuracy: 0.1768 - val_loss: 0.7105\n",
            "Epoch 321/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1698 - loss: 0.3853 - val_accuracy: 0.1760 - val_loss: 0.7236\n",
            "Epoch 322/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1749 - loss: 0.3816 - val_accuracy: 0.1753 - val_loss: 0.7144\n",
            "Epoch 323/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1722 - loss: 0.3643 - val_accuracy: 0.1735 - val_loss: 0.7096\n",
            "Epoch 324/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1714 - loss: 0.3759 - val_accuracy: 0.1660 - val_loss: 0.7149\n",
            "Epoch 325/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1685 - loss: 0.3775 - val_accuracy: 0.1720 - val_loss: 0.7211\n",
            "Epoch 326/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1703 - loss: 0.3848 - val_accuracy: 0.1590 - val_loss: 0.7288\n",
            "Epoch 327/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1690 - loss: 0.3707 - val_accuracy: 0.1865 - val_loss: 0.7157\n",
            "Epoch 328/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1718 - loss: 0.3799 - val_accuracy: 0.1685 - val_loss: 0.7221\n",
            "Epoch 329/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1718 - loss: 0.3779 - val_accuracy: 0.1795 - val_loss: 0.7096\n",
            "Epoch 330/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1742 - loss: 0.3711 - val_accuracy: 0.1743 - val_loss: 0.7209\n",
            "Epoch 331/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1739 - loss: 0.3770 - val_accuracy: 0.1628 - val_loss: 0.7202\n",
            "Epoch 332/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1714 - loss: 0.3771 - val_accuracy: 0.1775 - val_loss: 0.7140\n",
            "Epoch 333/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1727 - loss: 0.3907 - val_accuracy: 0.1768 - val_loss: 0.7070\n",
            "Epoch 334/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1713 - loss: 0.3783 - val_accuracy: 0.1797 - val_loss: 0.7211\n",
            "Epoch 335/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1709 - loss: 0.3765 - val_accuracy: 0.1760 - val_loss: 0.7058\n",
            "Epoch 336/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1716 - loss: 0.3877 - val_accuracy: 0.1780 - val_loss: 0.7160\n",
            "Epoch 337/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1719 - loss: 0.3839 - val_accuracy: 0.1712 - val_loss: 0.7262\n",
            "Epoch 338/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1695 - loss: 0.3841 - val_accuracy: 0.1700 - val_loss: 0.7190\n",
            "Epoch 339/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1718 - loss: 0.3741 - val_accuracy: 0.1775 - val_loss: 0.7119\n",
            "Epoch 340/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1732 - loss: 0.3717 - val_accuracy: 0.1772 - val_loss: 0.7073\n",
            "Epoch 341/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1724 - loss: 0.3758 - val_accuracy: 0.1830 - val_loss: 0.7176\n",
            "Epoch 342/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1710 - loss: 0.3776 - val_accuracy: 0.1775 - val_loss: 0.7113\n",
            "Epoch 343/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1718 - loss: 0.3712 - val_accuracy: 0.1752 - val_loss: 0.7107\n",
            "Epoch 344/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1709 - loss: 0.3829 - val_accuracy: 0.1750 - val_loss: 0.7207\n",
            "Epoch 345/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1698 - loss: 0.3745 - val_accuracy: 0.1770 - val_loss: 0.7170\n",
            "Epoch 346/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1705 - loss: 0.3813 - val_accuracy: 0.1743 - val_loss: 0.7248\n",
            "Epoch 347/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1722 - loss: 0.3755 - val_accuracy: 0.1735 - val_loss: 0.7157\n",
            "Epoch 348/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1707 - loss: 0.3802 - val_accuracy: 0.1823 - val_loss: 0.7121\n",
            "Epoch 349/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1698 - loss: 0.3773 - val_accuracy: 0.1770 - val_loss: 0.7183\n",
            "Epoch 350/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1721 - loss: 0.3828 - val_accuracy: 0.1778 - val_loss: 0.7126\n",
            "Epoch 351/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1718 - loss: 0.3787 - val_accuracy: 0.1713 - val_loss: 0.7248\n",
            "Epoch 352/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1711 - loss: 0.3794 - val_accuracy: 0.1612 - val_loss: 0.7394\n",
            "Epoch 353/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1715 - loss: 0.3794 - val_accuracy: 0.1680 - val_loss: 0.7220\n",
            "Epoch 354/500\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1726 - loss: 0.3797 - val_accuracy: 0.1690 - val_loss: 0.7271\n",
            "Epoch 355/500\n",
            "\u001b[1m 266/1688\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1614 - loss: 0.3775"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the training_history object contains the loss curves: training loss as `training_history.history[\"loss\"]` and validation loss as `training_history.history[\"val_loss\"]` (note the validation_split argument to model.fit set to 10%).\n",
        "\n",
        "Show the training and validation losses and comment: is the model overfitting? at what epoch did it start to overfit?"
      ],
      "metadata": {
        "id": "ztQ4wTXeoykj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(training_history.history[\"loss\"])\n",
        "plt.plot(training_history.history[\"val_loss\"])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.yscale('log') #use log scale for the y axis\n"
      ],
      "metadata": {
        "id": "c80Nmkw7IhXx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "d45f776d-3147-4108-87cf-0ff44afa3542"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'training_history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ecd4caddaae8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#use log scale for the y axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# is this model overfitting? how woudl you find out? how would you fix it?\n",
        "\n"
      ],
      "metadata": {
        "id": "NFwv_bNl9QEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given that the validation loss stops getting better and begins to rise while the training loss keeps getting less, the model is indeed overfitting. This shows that the model is ineffective at generalizing to new data since it is learning to suit the training set too closely.\n",
        "\n",
        "\n",
        "A way I would fix this is by reducing the amount of layers so that the data would be easier to memorize."
      ],
      "metadata": {
        "id": "LXbF23iDyXjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#what is the accuracy of the model? use model.evaluat to assess it\n",
        "\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "zXe-573CJ9Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the first 5 data points and corresponding predictions\n",
        "\n",
        "print(model.predict(x_test[:5])"
      ],
      "metadata": {
        "id": "sfg-VNAtI3Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:5]"
      ],
      "metadata": {
        "id": "r6kcQLODKJNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a ANN to solve the problem as a multiclass classification\n",
        "\n",
        "see slides for the apprioriate choices\n",
        "- use dense layers\n",
        "- choose the right number of neurons in output to solve a multiclass classification problem\n",
        "- choose the right activation function on the last layer for a multiclass classification problem\n",
        "- choose the right loss function for a multiclass classification problem"
      ],
      "metadata": {
        "id": "KM6IbzFFp3vT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modify the architecture hyperparametrs\n",
        "# set the last layer to a 10 nerons dense layer and set the softmax as the activation function for the last layer\n",
        "prob_model = tf.keras.models.Sequential()\n",
        "# add 1 dense layer with 128 neurons and relu activation function\n",
        "# add 1 dropout layers dropping 20% of the connections\n",
        "# add 1 dense layer at the end, how many neurons?\n",
        "# your code goes here\n",
        "prob_model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
        "prob_model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "prob_model.add(tf.keras.layers.Dropout(0.2))\n",
        "prob_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "prob_model.summary()\n",
        "prob_model.summary()"
      ],
      "metadata": {
        "id": "sKwIt-WbKPy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model)"
      ],
      "metadata": {
        "id": "UwzWCeHR90lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set the loss to be approprpate for the classification, the optimizer to Adam and compile and fit as before\n",
        "# NOTE: you can either use the Sparse Categorical Loss and leave the labels as they are or use the Categorical Loss but modify the labels to be one-hot-encoded (see slides from class on trees!)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer =tf.keras.optimizers.Adam()\n",
        "prob_model.compile = model.compile(optimizer = optimizer, loss = loss,\n",
        "              metrics=['accuracy'])\n",
        "prob_training_history = model3.fit(x_train, y_train, epochs=500, validation_split=0.1)"
      ],
      "metadata": {
        "id": "r7ye1w0eK3Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#what is the accuracy of the model? use model.evaluat to assess it\n",
        "\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "Hene5EG7Lo8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the first 10 data points and corresponding predictions\n",
        "\n",
        "result = prob_model.predict(x_test[:10])"
      ],
      "metadata": {
        "id": "WPu8ydTFMWTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show the loss curves and comment\n",
        "plt.plot(prob_training_history.history[\"loss\"])\n",
        "plt.plot(prob_training_history.history[\"val_loss\"])\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.yscale(\"log\") #use log scale for the y axis\n"
      ],
      "metadata": {
        "id": "yTGZvFBnMcsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss curves for training and validation are shown in this image. At first, both loses slowly go down, which means that learning is working. However, the validity loss starts to change and sometimes goes up, which is a sign of overfitting starting to happen. This behavior shows that the model is still learning from the training data, but it is getting worse at applying what it has learned to new data.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "koEpYyoX547r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a CNN (convolutional neural network) to solve the problem as a multiclass classification\n",
        "\n",
        "- you do not need the Flatten() layer anymore, the input size is not 728 but (28,28)\n",
        "- use Conv2D layers and MaxPool2D layers alternating them appropriately\n",
        "- use relu activation functions for the convolutional layers\n",
        "- add a dense layer at the end for the prediction\n",
        "- choose the right number of neurons in output to solve a multiclass classification problem\n",
        "- choose the right activation function on the last layer for a multiclass classification problem\n",
        "- choose the right loss function for a multiclass classification problem"
      ],
      "metadata": {
        "id": "k-252KDZLzIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "YOUR CODE GOES HERE\n"
      ],
      "metadata": {
        "id": "GwR59UszMQBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set the loss to be approprpate for the classification, the optimizer to Adam and compile and fit as before\n",
        "# NOTE: you can either use the Sparse Categorical Loss and leave the labels as they are or use the Categorical Loss but modify the labels to be one-hot-encoded (see slides from class on trees!)\n",
        "loss = ...\n",
        "optimizer = ...\n",
        "prob_model.compile...\n",
        "prob_training_history = ..."
      ],
      "metadata": {
        "id": "NtuT2mW5r5FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#what is the accuracy of the model? use model.evaluat to assess it\n",
        "\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "tmhi2mdGr5_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the first 10 data points and corresponding predictions\n",
        "\n",
        "result = prob_model.predict(x_test[:10])"
      ],
      "metadata": {
        "id": "MwHC9Ai2r-ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show the loss curves and comment\n",
        "plt.plot(.....\n",
        "plt.plot(.....\n",
        "plt.xlabel(....\n",
        "plt.ylabel(...\n",
        "plt.yscale('log') #use log scale for the y axis\n"
      ],
      "metadata": {
        "id": "9QhnqILIr72Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}